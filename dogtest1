# Install required dependencies
!pip install google-generativeai

# Import required libraries
from IPython.display import display, Javascript, Image, Markdown
from google.colab.output import eval_js
from base64 import b64decode
import cv2
import numpy as np
import PIL.Image
import io
import textwrap
import google.generativeai as genai

# Replace with your actual API key
API_KEY = "15849295c9d34290258d0df1d3c32007cfb55f8a"

# Configure Google Generative AI
genai.configure(api_key=API_KEY)

def js_to_image(js_reply):
    image_bytes = b64decode(js_reply.split(',')[1])
    jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)
    img = cv2.imdecode(jpg_as_np, flags=1)
    return img


def take_photo(filename='photo.jpg', quality=0.8):
    js = Javascript('''
    async function takePhoto(quality) {
      const div = document.createElement('div');
      const capture = document.createElement('button');
      capture.textContent = 'Capture';
      div.appendChild(capture);

      const video = document.createElement('video');
      video.style.display = 'block';
      const stream = await navigator.mediaDevices.getUserMedia({video: true});
      document.body.appendChild(div);
      div.appendChild(video);
      video.srcObject = stream;
      await video.play();

      await new Promise((resolve) => capture.onclick = resolve);

      const canvas = document.createElement('canvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      canvas.getContext('2d').drawImage(video, 0, 0);
      stream.getVideoTracks()[0].stop();
      div.remove();
      return canvas.toDataURL('image/jpeg', quality);
    }
    ''')

    display(js)
    data = eval_js(f'takePhoto({quality})')
    img = js_to_image(data)
    cv2.imwrite(filename, img)
    return filename


def to_markdown(text):
    formatted = textwrap.indent(text, '> ')
    display(Markdown(formatted))


filename = take_photo('photo.jpg')
print(f'Saved to {filename}')
display(Image(filename))
img = PIL.Image.open(filename)
process_dog_image(img)



from vertexai.generative_models import GenerativeModel

def process_dog_image(img):
    model = GenerativeModel("gemini-1.5-pro")

    try:
        # Generate detailed breed and nutritional information
        prompt = ("What breed is this dog? Provide weight and nutritional information. "
                  "Format it as a list and suggest food brands.")

        response = model.generate_content([prompt, img])

        # Ensure response has text before printing
        if response and hasattr(response, 'text'):
            print(response.text)
        else:
            print("No valid response received.")

    except Exception as e:
        print("Error during processing:", e)
        print("Ensure your Vertex AI setup is correct and that you have access to 'gemini-1.5-pro'.")
